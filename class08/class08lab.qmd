---
title: "Class 08 Mini Project"
author: Catherine Diep
format: html
---

# Exploratory Data Analysis

```{r}
#read.csv("https://bioboot.github.io/bimm143_S20/class-material/WisconsinCancer.csv")
```

```{r}
fna.data <- read.csv("https://bioboot.github.io/bimm143_S20/class-material/WisconsinCancer.csv")

#Save input data file into project directory

wisc.df <- data.frame(fna.data, row.names=1)

head(wisc.df)
```

```{r}
#Remove the 1st column 
wisc.data <- wisc.df[,-1]

#Create diagnosis factor for later
diagnosis <- as.factor(wisc.df[,1])
```

> Q1. How many observations are in this dataset?

```{r}
nrow(wisc.data) #number of observations
```

> Q2. How many of the observations have a malignant diagnosis?

212 observations

```{r}
table(wisc.df$diagnosis) #numbers of benign and malignant diagnoses
```

> Q.3 How many variables/features in the data are suffixed with \_mean?

```{r}
#colnames(wisc.df)
length(
grep("_mean", colnames(wisc.df))) #Number of column names with "_mean"
```

# Principal Component Analysis

First, we need to consider whether the data needs "scaling" to make our comparison fair.

Yes, we need to scale because the means of the columns are very different.

```{r}
# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp(wisc.data, scale=TRUE)
```

```{r}
# Look at summary of results
y <- summary(wisc.pr)
attributes(y)
```

> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

44.27%

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

3 PCs

```{r}
which(y$importance[3,] >= 0.7) [1]
```


> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

7 PCs

```{r}
which(y$importance[3,] >= 0.90) [1]
```


# Interpreting PCA results

Making a biplot of the data 

```{r}
biplot(wisc.pr)
```

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

No patterns stand out, because this graph is too messy and difficult to understand. 

Let's make a PC plot (a.k.a. "score plot" or "PC1 vs PC2" plot)

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis)
```
>Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col=diagnosis)
```

These plots show that there is a clear separation between the sequences for malignant and benign tumors, as shown by the clear division between the areas of red (malignant) and black (benign) data points. 

```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

>Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

 -0.26085376

```{r}
#wisc.pr$rotation[,1]
```

>Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
which(y$importance[3,] >= 0.80) [1]
```

#Hierarchical Clustering

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```

```{r}
data.dist <- dist(data.scaled)
```

```{r}
wisc.hclust <- hclust(data.dist)
```

>Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

The height is 19. 

```{r}
plot(wisc.hclust)
abline(a=19, b=0, col="red", lty=2 )
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4) #Cut into the 4 clusters

table(wisc.hclust.clusters, diagnosis)
```


## Combine PCA with clustering 
I want to cluster in "PC space"

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis)
```

```{r}
#wisc.pr$x #Patients on each PC
```

The 'hclust()' function wants a distance matrix as input...

```{r}
d <- dist(wisc.pr$x[,1:3])
wisc.pr.hclust <- hclust(d, method = "ward.D2")
plot(wisc.pr.hclust)
```

>Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

Yes, cut into 2 clusters.

Find my patient's membership vector with the 'cutree()' function. 

```{r}
grps <- cutree(wisc.pr.hclust, k=2)

table(grps)
```

```{r}
table(diagnosis, grps)
```

Can see potential misdiagnoses and false positives from this table. 

>Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

'ward.D2' is my favorite method because it results in the clearest clustering with more distinct groups than the other methods. 

>Q14.

```{r}
wisc.km <- kmeans(wisc.data, centers= 2, nstart= 20)
```


>Q15. How well does the newly created model with four clusters separate out the two diagnoses?

The newly created model separates out the two diagnoses better than the kmeans; the majority of the malignant cases are in the 1st cluster while the majority of the benign cases are in the 3rd cluster. However, this sorting is not completely inefficient data was misclassified and sorted into 4 instead of 2 groups. 

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
table(wisc.pr.hclust.clusters, diagnosis)
```

>Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

k-means and the hierarchical clusters were not as effective at separating the diagnoses. K-means did not separate the diagnoses efficiently, as there was only 1 benign tumor with 130 malignant ones, while there were 82 malignant tumors with 356 benign ones. These 82 malignant tumors were misclassified as benign. Meanwhile, the pre-PCA hierarchical clustering sorted the data into 4 different groups (not the 2 that we expect). Meanwhile, the PCA clustering sorted the data into 2 clear groups. 

```{r}
table(wisc.km$cluster,diagnosis) #kmeans
table(wisc.hclust.clusters, diagnosis) #hierarchical
table(wisc.pr.hclust.clusters, diagnosis) #pca
```

>Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

The PCA analysis resulted in the most specificity, while the Kmeans analysis resulted in the highest sensitivity. 

```{r}
#Sensitivity
kmeans <- 130/(130 + 82)
kmeans
hclust <- 165/(165+5+40+2)
hclust
PCAclust <- 179/(179+33)
PCAclust
```
```{r}
#Specificity 
kmeanss <- 356/(356+1)
hclusts <- 343/(343+12+2)
PCAclusts <- 333/(333+24)

kmeanss
hclusts
PCAclusts
```


# Prediction

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```
>Q.18 Which of these new patients should we prioritize for follow up based on your results?

Patient 2 


