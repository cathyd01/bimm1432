---
title: "Class 7 - Machine Learning 1"
author: Catherine Diep 
format: html
---

# K-means clustering 

First, we will test how this method works in R with some made up data. 

```{r}
x <-rnorm(10000)
hist(x)
```

Let's make some numbers centered on -3 


```{r}
tmp <- c(rnorm (30, -3), rnorm (30, +3))

x <- cbind(tmp, rev(tmp))

plot(x)
```

Now let's see how 'kmeans()' works with this data...

```{r}
km <- kmeans(x, centers = 2, nstart=20)
km
```

```{r}
km$centers
```

> Q. How many points are in each cluster?

```{r}
km$size
```

> Q. What ‘component’ of your result object details cluster assignment/membership? Cluster center?

```{r}
km$cluster
```

```{r}
km$centers
```

> Q. Plot x colored by the kmeans cluster assignment and add cluster centers as blue points

```{r}
plot(x, col=km$cluster)
points(km$centers, col="blue", pch=15, cex=1.5)
```

# Hierarchical clustering 

The 'hclust()' function in R performs hierarchical clustering. 

The 'hclust()' function requires an input distance matrix, which I can get from the 'dist()' function. 

```{r}
hc <- hclust(dist (x))
hc
```

There is a plot() method for hclust objects...

```{r}
plot(hc)
```

Now to get my cluster membership I need to "cut" the tree to yield separate "branches" with the "leaves" on each branch  being our cluster. To do this we use the 'cuttree()' function. Specify h=height at which the tree should be cut. 

```{r}
cutree(hc, h=8)
```

Use 'cutree' with a k=2 to specify the number of groups it should be cut into. 

```{r}
grps <- cutree (hc, k=2)
```

A plot of our data colored by our hclust grps

```{r}
plot (x, col=grps)
```

# Principal Component Analysis (PCA)

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
```

> Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

```{r}
nrow(x)
ncol(x)
```

Preview the 1st 6 rows 

```{r}
head(x)
```
```{r}
# Note how the minus indexing works
#rownames(x) <- x[,1]
#x <- x[,-1]
#head(x)
```
Finding the new number of rows and columns 

```{r}
#dim(x)
```

A better way to name the 1st column as labels 

```{r}
x <- read.csv("https://tinyurl.com/UK-foods", row.names=1)
head(x)
```

>Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

The second method of labeling the 1st column as 'row.names' works best, because each time you run the minus indexing, another column "disappears". 

```{r}
barplot(as.matrix(x), beside = T, col=rainbow(nrow(x)))
```

>Q3: Changing what optional argument in the above barplot() function results in the following plot?

Changing the beside argument to false. 

```{r}
barplot(as.matrix(x), beside = F, col=rainbow(nrow(x)))
```

```{r}
pairs(x, col=rainbow(10), pch=16)
```

>Q5: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

While this is kind of useful, it takes work to dig into the details here to find out what is different in these countries. If a point is on the diagonal, the value  of food consumed is the same for both countries. 

## PCA to the rescue 

Principal component analysis (PCA) can be a big help in these cases where we have lots of things (dimensions) that are measured in a data set. 

The main PCA function in base R is called 'prcomp()'. This function wants the transpose of our food matrix/table/data.frame. 

```{r}
pca <- prcomp( t(x))
summary(pca)
```

The above result shows that PCA captures 67% of the total variance in the original dta in one PC and 96.5% in two PCs. 

```{r}
attributes(pca)
```

```{r}
head(pca$x)
```

Let's plot our main results. 

```{r}
plot(pca$x[,1], pca$x[,2], col=c("orange", "red", "blue","green"))
```

```{r}
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2 )
```

# PCA of RNA-seq Data

```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
```
>Q10: How many genes and samples are in this data set

100 genes and 10 samples

```{r}
dim(rna.data)
```

```{r}
## Again we have to take the transpose of our data 
pca <- prcomp(t(rna.data), scale=TRUE)
 
## Simple un polished plot of pc1 and pc2
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2")
```

```{r}
summary(pca)
```

```{r}
plot(pca, main="Quick scree plot")
```

```{r}
## Variance captured per PC 
pca.var <- pca$sdev^2

## Percent variance is often more informative to look at 
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
pca.var.per
```

```{r}
barplot(pca.var.per, main="Scree Plot", 
        names.arg = paste0("PC", 1:10),
        xlab="Principal Component", ylab="Percent Variation")
```

```{r}
## A vector of colors for wt and ko samples
colvec <- colnames(rna.data)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"

plot(pca$x[,1], pca$x[,2], col=colvec, pch=16,
     xlab=paste0("PC1 (", pca.var.per[1], "%)"),
     ylab=paste0("PC2 (", pca.var.per[2], "%)"))

text(pca$x[,1], pca$x[,2], labels = colnames(rna.data), pos=c(rep(4,5), rep(2,5)))
```

